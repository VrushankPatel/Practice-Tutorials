# Docker basics

# Docker : Docker is a set of platform as a service products that use OS-level virtualization to deliver software in packages called containers.
# You can create image or bundle image of your deployment files and configuration, which is platform-free and can be used in any platform.
# and then you can ship that image anywhere (Any machine) to deploy.

# Visit Docker Hub and create account there to interact with docker registry.

# to login to docker hub via command line.
>> docker login

# to logout from docker hub via command line.
>> docker logout

# to get the info about docker version, driver, server, containers and many more things about docker.
>> docker info

# to get docker version, goLang version, api version and other techno-stack versions.
>> docker version

# to get only docker version
>> docker -v
OR
>> docker --version

# to get information about docker, server, containers, images, it's drivers etc.
>> docker info

# for docker topics help
>> docker --help

# Docker image : Docker images are the templates used to create Docker containers.
# Docker images are stored in docker registry (Docker hub registry).
# A Docker image is a read-only template that contains a set of instructions for creating a container that can run on the Docker platform. 
# It provides a convenient way to package up applications and preconfigured server environments, which you can use for your own private use or share publicly with other Docker users.

# Docker Container : Container is  a running instance of an docker image.
OR
# Docker container : Container is something, on which docker image runs.
OR 
# Docker Container : Docker provides the ability to package and run an application in a loosely isolated environment called a container.
# Containers are isolated from one another and bundle their own software, libraries and configuration files; they can communicate with each other through well-defined channels.

# if we want help for specific docker command
>> docker images --help
OR
>> docker run --help

# to get all the docker images we've in our machine
>> docker images

# to get any docker image from docker hub, we've to get that image's name from it's repository and then we can use docker pull command to pull image.
# here, let's try for ubuntu server. we'll grab ubuntu's image from docker hub. image name is ubuntu. so, the command is...
>> docker pull ubuntu
# it'll pull the ubuntu image.
# there might be multiple versions of ubuntu in ubuntu's docker registry or repository.
# by default, it'll pull latest version.

# let's assume thet we need version 18.04 of ubuntu docker image, which we've to pull.
# for that, we've to use tag to show the exact version of image. version of images is available in that image's registry in docker hub.
# let's retrieve 18.04 version of ubuntu image.
>> docker pull ubuntu:18.04
# it'll pull 18.04 versioned image of ubuntu.

# to explore docker public repositories, try https://hub.docker.com/search?q=&type=image

# image's name and tag syntax look like this -->  {image_name}:{tag}
# by default tag is latest, so here in our case, name and tag will be like --> ubuntu:latest

# now, we've cloned one docker image named ubuntu:latest, let's check it's id.
# with docker images command, -q (quite mode flag) flag will return the image id.
>> docker images -q
# if we've cloned only one docker image, it'll show it's id, copy the id because we're going to use it.

# if we want to get all the details about images, then insted of using -q flag, use -a flag, that means all details.
>> docker images -a

# if we want to filter images, then we can use -f flag.
>> docker images -f "dangling=true"
# it'll show all the dangling images, dangling images are the images, which are not used atleast once and not assiciated with any running containers are known as dangling images.

# we can use the filter with quite mode, we can use them together.
>> docker images -f "dangling=false" -q
# it'll show all the non-dangling image's ids.

# to remove the image, we can use rmi command which means remove image. copy the ubuntu image id by getting it via -q flag, and use it here.
>> docker rmi {ubuntu_image_id}
{In_My_Case}[> docker rmi f643c72bc252]

# now, try to retrieve all the images again, you'll notice that docker image of ubuntu is no longer there.

# docker images run in the docker containers.
# we've docker ps command for containers, check that command flags and description by..
>> docker ps --help

# ps is used to show all the containers.
>> docker ps
# it'll list all the running containers, if you've one.
# if you want to see the containers those are not running currently, then append above command with -a flag.
>> docker ps -a
# it'll show you the stopped and terminated containers as well.

# to check the pulled image, we can use inspect command of docker.
>> docker inspect ubuntu
# it'll show all the information of ubuntu image like it's tags, RepoTags, DataDirs, GraphDriver, Root FileSystem, MetaData, virtual size, ContainerConfig etc.

# let's run an image for demo, we just deleted ubuntu image to learn rmi command. pull that image again.
# here, we'll deal with ubuntu server image, we want to use it like a ubuntu machine. 
# so, we want to interact with ubuntu terminal here. for that, we've to use run command's -i and -t flag.
# check the run command of docker by --help after it, you can see -i is interactive mode and -t is to allocate pseudo tty.
# so, combine -i and -t means -it, we've to use -it.
>> docker run -it ubuntu
# above command will run ubuntu server and bring you to the ubuntu terminal.

# if we want to give the container a name, then we can provide name with run command by --name flag.
>> docker run --name MyUbuntuContainer -it ubuntu bash
# in above query, we passed container name as MyUbuntuContainer. 
# And, after image name, we've passed the shell's mode of ubuntu which is bash, we can pass bash, dash etc.

# now, ubuntu image is running, and you're inside the terminal of that running docker ubuntu-server image.
# so, basically docker image is running in some docker container.
# to check the running container, we've to open another terminal or cmd.
# open other terminal or cmd, and run the ps command.
>> docker ps
# it'll show you the running container where ubuntu image is running.

# copy the container ID from the details of container where ubuntu image is running.
# we can now start and stop the running of ubuntu image by that container id directly.

# in this case, our container is already running in other terminal. let that terminal as it is.
# in the new terminal, let's stop the ubuntu container by stop command of docker.
>> docker stop {container_id}
OR
>> docker stop {Container_Name}
# now, go back to ubuntu terminal, you can see the exit command is automatically inserted and ubuntu server is now stopped because we just stopped it's container.
# similarly, to start the same container...
>> docker start {container_id}
OR
>> docker start {Container_Name}
# now, if you start the ubuntu container again, then it'll start in the background, you'll not be connected to ubuntu image's -it mode.
# you've to attach to that container's running session. for that, you can use attach command.
>> docker attach {container_id}
OR
>> docker attach {Container_Name}

# to temporarily stop container or to pause the container... use pause command.
# first start the container or run image of ubuntu with interactice mode of bash, then try below command.
>> docker pause {container_id}
OR
>> docker pause {Container_Name}
# after running this command, check the terminal where the ubuntu image is running in -it mode, you'll not able to pass any command there, because it is paused.
# We've to unpause that container. for that, use unpause command.
>> docker unpause {container_id}
OR
>> docker unpause {Container_Name}
# now check the terminal where ubuntu session of image is running, it should back in active mode or in the nutshell, resumed.

# now, docker stop command gracefully shutdown the docker image, for here, it inserted exit command, and shut downed the running instance of ubuntu image.
# But, what if, ubuntu instance is busy in some other process, in that case, stop command will wait to release that execution thread, and then stop it.
# But here, we want to terminate the existing process and stop it, for that, kill command can be used as given below.
>> docker kill MyUbuntu
# now, check the terminal where ubuntu image instance was running, you'll notice that instance is terminated without insertion of exit command.

# so, the difference between stop and kill is stop command stop the process and insert exit command for gracefully shutdown, where kill command just terminate the instance (just like we used to plug out the cable of computers incase of hanging.ðŸ˜‚)

# to remove the container, we can use rm command.
>> docker rm {container_id}
OR
>> docker rm {Container_Name}

# To delete all the containers from our machine, try below command, and understand it properly.
>> docker container rm $(docker container ls â€“aq)
# "$(docker container ls â€“aq)" will return all the container's id. and rm will remove them one by one.

# while running image, if we don't provide name to container, docker will pickup a random name (Try it ðŸ˜‰).

# now, run the {docker run -it ubuntu} command again in old terminal, you can give the name of the container if you want.
# we'll see the docker stats console monitor now.
# while the ubuntu image is running, open the another terminal, and use below command.
>> docker stats
# it'll show you the docker's all the running containers, their allocated memory (usage), limit of memory etc.
# this is continous monitor, use Ctrl+C to exit from it.

# to see the stats of specific container, append above command by container name.
>> docker stats {container_id}
OR
>> docker stats {Container_Name}

# exit from the docker stats by Ctrl+C, and enter below command to heck the system-docker related info.
>> docker system df
# it'll show you number of images, containers, any of active of them, size, reclaimable or not etc.

# to display the running processes of a container, we can use top command of the docker
>> docker top {container_id}
OR
>> docker top {Container_Name}

# dangling images : docker images which are not used atleast once and not assiciated with any running containers are known as dangling images.
# there is docker system prune command, but be careful while using this one, it can remove all the dangling images and all stopped containers.
# first of all, check what that command does by docker system prune --help.
# there are two main flags for it, one is -a, which can remove all the non containerized images not just dangling images.
# and second flag is -f, which can forcefully remove the images, so, it'll not ask you to confirm about deleting the images, it'll just delete is forcefully.
>> docker system prune
# it'll ask you for confirmation by y/N
# choose your option y or n and check the images and containers to check if it worked or not.
# if container is not removed, you've to stop it first and then try prune.

# ubuntu image might not be deleted by above command, because it is not dangling image, we've used it atleast once or twise.
# to remove all the non containerized images, we've to use -a flag.
>> docker system prune -a
# press y to confirm and then check the images, ubuntu image should've deleted.

# to check the history of particular image, we can use history command in docker.
>> docker history {image_name}
{In_My_Case}[> docker history ubuntu ðŸ˜„]

# Now, there is one thing needed to be understand that everything that docker runs from image to container, is a in-memory execution.
# once you stop docker instance and run it again with new container, all the old files configured with image and container will be lost.
# So, let's try this with example.
# Jenkins and Teamcity are the CI/CD tool, that provides functionality to continously integrate and deliver the updates that we develop.
# Both of them are standalone servers, and their docker image is available on docker hub.
# We'll try Jenkins here, but you can try teamcity if you want.

# Let's pull jenkins image first.
# jenkin's latest tagged image was not on manifest of registry, so i'll pull the latest image by it's version number.
>> docker pull jenkins:2.60.3

# now, jenkins use 2 ports, one is 8080, where we use web gui from browser, and another is 50000, where jenkins API exposes.
# when we run jenkins image, it'll run jenkins on ports 8080 and 50000 of container (consider it as a kind of VM).
# we can't access jenkins on 8080 and 50000 ofour machine, so we've to forwars the port of container to our machine's port.
# let's assume that we want to forward port 8080 of container to port 1111 of our machine.
# and we want to  forward port 50000 of container to port 2222 of our machine.
# then, we can specify the ports by -p flag after run command. then we've to use syntax like given below.
# ==> -p {OUR_MACHINE_PORT}:{CONTAINER_PORT} -p {OUR_MACHINE_PORT}:{CONTAINER_PORT}
# in this case ==> -p 1111:8080 -p 2222:50000

# to run jenkins as we described above, use below command.
>> docker run -p 1111:8080 -p 2222:50000 jenkins:2.60.3
# Now, you'll able to access jenkins on port 1111 on browser. check the logs of above command, at the end, it'll provide a hex coded password.
# copy that password, because you'll need it to access jenkins. access localhost:1111, use the copied password as administrator password.
# in there, it'll ask you to install plugins, choose "install selected plugins", then select none of the plugins (0 plugins) and choose install => save => next.
# once, you're inside jenkins, create one demo project without configuration. this project will be stored in the file system of running container.

# Now, get container id by (docker ps -aq), stop the container by stop command and container id, start the container by docker start command and container's id again.
>> docker ps -aq
>> docker stop {container_id}
>> docker start {container_id}
# you can still access jenkins again on 1111, and you can use previously copied password and admin as user, and you'll see your demo project is still there.

# now, stop that container, so the jenkins will be stopped. and delete the container by rm command and container id (docker ps -aq). 
>> docker stop {container_id}
>> docker rm {container_id}
# Now run the same docker image by docker run command, and try to access jenkins at port 1111. you'll see everything is now resetted.
# you've to use new admin password from log, you've to reinstall plugins, and you'll notice that your demo project is now gone.

# basically, whenever we change or remove the container, docker remove all it's data. we need some persistance storage solution to store the data of running image.
# we can use our local machine's path to store those data from image to our machine. we can pass -v (volume) flag to connect two paths, one side is our machine's path, other side is container's path.
# in this case, we'll connect our desired path to jenkins_home path of congainer.
# syntax => -v {Our_Path}:{/var/jenkins_home}
# /var/jenkins_home is the path where jenkins stores it's data. So now, jenkins will store the data at our desired directory.

# jenkin's official registry on docker hub says that, you should run the jenkins something like givn below.
>> docker run -p 8080:8080 -p 50000:50000 -v {Your_Path_For_Jenkins_Data}:/var/jenkins_home jenkins:2.60.3
# which is right, that's how we can use persistant storage for jenkins over docker.

# Bind Mount : Here, we'll provide our directory to store data from container which is called bind mount.
# In my case, jenkins named folder is located in desktop in my mac, so, i'll use that path.
>> docker run -p 8080:8080 -p 50000:50000 -v /Users/vrushankpatel/desktop/jenkins:/var/jenkins_home jenkins:2.60.3
# Now, all the files of jenkins will be stored in the jenkins folder located in desktop in my case, you should check your directory that you specified.
# now, once jenkins is online, copy the password from log again and access gui at 8080, setup everything and create demo job in there.
# now stop the container, delete the container, and restart everything by above docker run command which will run everything again with new container.
# now, if you access port 8080, you've to login by admin and past copied password and then, you'll see nothing is lost, everything that you setup earlier and that demo job is as it is since we're using persistant storage.

# in above case, we used our local machine's path to store jenkins data.
# in the future, we might need to use multiple servers like jenkins, teamcity etc. we can not use different directories like this to persist the storage because it will be a bit messy.
# we've to store all the docker specific files in some specific location of machine.
# to create and manage that storage, docker provides the functionality of docker volumes.
# if we create docker volume, it'll create that named directory somewhere in our machine (Path is different for different OS), which can be used for image-containers running (persist storage).

# let's create a volume for jenkins server.
>> docker volume create myjenkins
# it'll create volume named myjenkins.

# to list all the volumes.
>> docker volume ls
# our new volume will be appear there.

# now, we'll use this new volume for the docker run command of jenkins.
# Syntax : -v {volume_name}:/var/jenkins_home
>> docker run -p 8080:8080 -p 50000:50000 -v myjenkins:/var/jenkins_home jenkins:2.60.3
# now, it'll run jenkins and persist it's storage in our new volume myjenkins.

# if we want to know, where that docker volume is mounted, we can inspect it in other terminal.
>> docker volume inspect myjenkins
# it'll show you where is it mounted, when it was created and etc.

# to delete volume,
>> docker volume rm myjenkins

# to delete all unused volumes,
>> docker volume prune

# to inspect the running container, we can inspect that also.
>> docker inspect (container_id)
OR
>> docker inspect (Container_Name)
# it'll show you when it was created, where is it's vlume mounted and other metadata.

# How to create our own docker image ?
# We have to create Dockerfile (without any extension) to build our own image.
# create Dockerfile in somewhere in your pc's folder, open cmd or terminal in it.
# here is a sample body of Dockerfile, read it carefully and build your image also by editing Dockerfile.
###
    # first of all, we've to import our base image, for that, we've FROM keyword.
    # we're using ubuntu base image here, but if you don't want to use any other image, then you can try SCRATCH.
    # FROM SCRATCH means no base image, just start from scratch to create our own platform image.
    FROM ubuntu

    # if you want to show the maintainer of docker image, then you can use below line, otherwise it is optional.
    MAINTAINER vrushank patel <your@emailId.com>

    # RUN will attach command to be run exactly when image is executed in container.
    RUN apt-get update

    # CMD will execute them command when machine is ready and on state (RUN commands will be executed before this).
    # we'll split commands as a sequence of words in here.
    CMD ["echo", "Hello world...! from my first docker image.."]
###

# We just created dockerfile to build our image. now bring your terminal path to Dockerfile, and run docker build.
# Syntax : docker build -t {image_name}:{tag_name} .
# tag_name is optional, by default it'll be latest.
# . (dot) means Dockerfile is in the root of where your terminal is.
# if you're not in the root of Docker file, then you've to provide the path where Dockerfile exists, then syntax will be...
# Syntax : docker build -t {image_name}:{tag_name} {Path_To_Dockerfile}
>> docker build -t sample_ubuntu:1.0 .

# check image..
>> docker images

# check the image info.. (copy the image id from above command's output or we can use name)
# Syntax : docker image inspect {image_id}
OR
>> docker image inspect sample_ubuntu:1.0
# it'll show you image info, you'll find out that author is the MAINTAINER from dockerfile.

# now run the image..
>> docker run sample_ubuntu:1.0
OUTPUT : Hello world...! from my first docker image..

# in Microservices architecture, we'll have multiple microservices, each of them will have their own docker image.
# we'll have to manage multiple docker images, for that, docker compose comes to the picture.
# if docker-compose command doesn't work, then you've to install it separately (just google it) or try (pip install -U docker-compose).
# Using Compose is basically a three-step process: 
## Define your app's environment with a Dockerfile so it can be reproduced anywhere. 
## Define the services that make up your app in docker-compose.yml so they can be run together in an isolated environment. 
## Run docker-compose up and Compose starts and runs your entire app.

# check docker-compose version and other metadata.
>> docker-compose -v
OR
>> docker-compose --version

# check more info
>> docker-compose version

# let's create a docker compose, given is the body of docker-compose file, read cmments in it to understand it.

###
    # first of all, we'll define version of docker compose file.
    version: '3'

    # now, we've to define all the services, where our docker images will work as a service.
    services:
      web:
        # first, we'll define port where our nginx will be exposed.
        # {our_port}:{container_port}, we'll expose nginx port 80 of container to our machine's 9090
        ports:
        - 9090:80/tcp
        
        # Now, we'll define image which will be pulled.
        image: nginx
    
      # now, we'll define database service here for example purpose. we'll use redis.
      database:
        image: redis
###

# once you create above file in somewhere in your pc, bring your cmd or terminal path to there and enter below command to validate docker-compose file.
>> docker-compose config
# if it write whole file again, then the file is validated, if it gives error, just google, it is easy to solve it.

# let's run it by up command.
>> docker-compose up
# it'll download the nginx and redis image, and then it'll run them, we can access nginx on port 9090 on our machine, open browser and try it.

# open other terminal and use (docker ps), you'll see nginx and redis running on containers.
# now, the only problem here is in our terminal, logs are going on, if we press Ctrl + C, then docker-compose will stop.
# we want to run docker-compose in background or detached screen, for that, we can use -d flag with up.
# before that, press Ctrl + C to stop the currently running docker-compose, then we've to officialy down the docker-compose, so try below command.
>> docker-compose down
# it'll stop the docker-compose's all the processes and remove the containers, try (docker ps -a), all the containers of redis and nginx should be removed by now.

# now, let's run the docker compose in detached mode.
>> docker-compose up -d
# it'll run docker-compose services in background mode.

# The good thing about docker-compose is it provide us facility to scale our services we written in docker-compose.yml.
# if we use --scale flag, and provide the number of replication for any service, then it'll scale that service for us.
# we'll see that by example given below.
# so, let's assume that we want to scale nginx to be replicated by 4 times, which means 4 different nginx from one image will run.
# so, we can distribute the load accordingly by external load balancer, we've nginx in web service (check in the program body), so we'll scale web here.
# for that, we can try below command to scale web service.
>> docker-compose up --scale web=4
# based on above command, 4 instances of nginx server should expose, but it'll give you an error here.
# because, check the web service part of docker-compose.yml, we've defined ports like - 9090:80/tcp.
# it is running first instance and exposing it on 9090, then for second instance, it'll try o expose it on 9090 only which is now reserved by first instance.
# if we don't provide ports in web service part of docker-compose, then it'll expose the instance by choosing random ports.
# but, here, we've provided 9090, so it'll try to expose all the instances on 9090 only, which is not possible.

# So, we've to provide range of port which can be used to replicate the server of service.
# we'll provide the port range from 9090 to 9100 for nginx web service here.
# So, open the docker-compose.yml file, and edit the ports part as given below.
###
    ports:
    - 9090-9100:80/tcp
###
# now, here, we're providing 10 ports inside port range, so, it'll randomly choose ports from those 10 ports to scale nginx and run it.
# but if we want to scale this service for more then 10 times replication, then we've to increase this range.

# now, assuming that you've changed from static port to the port range given above, let's run nginx with scaling.
>> docker-compose up --scale web=4 -d
# it'll randomly choose 4 ports from port range, and expose nginx in all of them.
# how'll we know that on what port, the nginx is running?
# for that, check containers.
>> docker ps
# it'll show you all the containers, nginx is scaled at 4 times replication, so 4 running containers of nginx should appear there.
# in the ports column, you can see the respactive port assigned by particular container, access that port, and you'll see that nginx is exposed in all of them.
# if we want to balance the load between all these nginx, the ports are exposed, we can do it via external load balancer.

# run docker-compose down to down all the services and to remove all the containers.

# Open the google and check for the word HAProxy, it is a proxy server like nginx which can be used for load balancing.
# in here, we scaled our web service, which was exposed on different ports. But now, below description is what we want.
# description : We want to expose only one port 8080 where nginx shouls be accessed. we want to replicate the nginx 10 times.
# but, we don't want to expose all 10 replications of nginx on different ports. we want to expose only one port 8080.
# and whenever we access port 8080, each request should go to different different replication of nginx.
# i.e first request should go to first replication (instance) of nginx, second should go to second instance, we've 10 replications, so 11th request should go to again first replication and so on.
# in the nutshell, we want to distribute the request load among all 10 replications of nginx.
# for that, we'll use HAProxy, HAProxy will work as a LB (Load Balancer) and will be exposed on 8080.
# and nginx will not exposed directly, but inside the container, it'll replicated 10 times.
# below is the docker-copose.yml body, read and understand it carefully.

###
version: '3'
services:
  # in web, we define image of nginx.
  web:
    image: nginx
  # for load balancing via HAProxy, we'll give lb as a name of service.
  lb:
    # image is dockercloud/haproxy, it will be pulled.
    image: dockercloud/haproxy
    # links will connect to web means web service we just defined above.
    # link we'll use is - web, so, load will be balanced between all the scales or replications of - web. we can use multiple links here.
    links:
    - web
    # HAProxy will run on port 80 of container, and it'll be forwarded to 8080 port of our machine.
    ports:
    - 8080:80
    # shared volume for all the replication is given below.
    volumes:
    - /var/run/docker.sock:/var/run/docker.sock
###

# now, once you write above body, run these commands..
# to validate
>> docker-compose config 
# to run
>> docker-compose up --scale web=6
# it'll run docker-compose and create 6 replicas of web instance.
# now try this in another terminal..
>> docker ps
# it'll show you 6 running containers of nginx, and one for HAProxy.
# those 6 containers have no ports exposed to our local machine, but HAProxy has a port exposed as 8080 (we declared in body).
# now keep terminal and browser side by side.
# in browser, access localhost:8080.
# it'll show you welcome page of nginx. and at a log side, it'll show you the log of which instance or replication is getting accessed like web1 or web2.
# reload the page in browser, and the log in terminal will show you on which replication, the request is going, everytime you reload the page, the request will go to different instances or replicas of nginx.
# basically we've distributed the load between 10 different replicas of nginx here by HAProxy.


